{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-02T12:11:35.781679Z",
     "iopub.status.busy": "2026-01-02T12:11:35.781079Z",
     "iopub.status.idle": "2026-01-02T12:12:56.294291Z",
     "shell.execute_reply": "2026-01-02T12:12:56.293503Z",
     "shell.execute_reply.started": "2026-01-02T12:11:35.781646Z"
    },
    "id": "NGladb8gtkDl",
    "outputId": "85202635-d8e6-4ae1-a944-3b432044366e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m988.2/988.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.0/23.0 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -Uq \"trl[peft]\" trackio bitsandbytes liger-kernel wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:12:56.296223Z",
     "iopub.status.busy": "2026-01-02T12:12:56.295958Z",
     "iopub.status.idle": "2026-01-02T12:12:56.332436Z",
     "shell.execute_reply": "2026-01-02T12:12:56.331816Z",
     "shell.execute_reply.started": "2026-01-02T12:12:56.296195Z"
    },
    "id": "tXw0tx-ktkDm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "hf_token = \"YOUR_HUGGINGFACEHUB_TOKEN_HERE\"\n",
    "wanbd_token = \"YOUR_WANDB_TOKEN_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:12:56.334010Z",
     "iopub.status.busy": "2026-01-02T12:12:56.333384Z",
     "iopub.status.idle": "2026-01-02T12:12:57.073018Z",
     "shell.execute_reply": "2026-01-02T12:12:57.072445Z",
     "shell.execute_reply.started": "2026-01-02T12:12:56.333986Z"
    },
    "id": "3aS9rb8xtkDm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:12:57.074726Z",
     "iopub.status.busy": "2026-01-02T12:12:57.074481Z",
     "iopub.status.idle": "2026-01-02T12:13:05.550811Z",
     "shell.execute_reply": "2026-01-02T12:13:05.550186Z",
     "shell.execute_reply.started": "2026-01-02T12:12:57.074680Z"
    },
    "id": "j6kKfstWtkDm",
    "outputId": "7515197b-a0b5-4a4a-d84c-5704ea0f053c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleviettin\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(wanbd_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:13:05.551983Z",
     "iopub.status.busy": "2026-01-02T12:13:05.551607Z",
     "iopub.status.idle": "2026-01-02T12:13:05.555998Z",
     "shell.execute_reply": "2026-01-02T12:13:05.555173Z",
     "shell.execute_reply.started": "2026-01-02T12:13:05.551957Z"
    },
    "id": "BVWHG2ivtkDm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"DPOTraining\"  # name your W&B project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:13:05.557241Z",
     "iopub.status.busy": "2026-01-02T12:13:05.556922Z",
     "iopub.status.idle": "2026-01-02T12:13:05.575429Z",
     "shell.execute_reply": "2026-01-02T12:13:05.574826Z",
     "shell.execute_reply.started": "2026-01-02T12:13:05.557205Z"
    },
    "id": "frbAL3metkDn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_id, output_dir = \"meta-llama/Llama-3.2-3B-Instruct\", \"Llama-3.2-3B-Instruct-DPO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "08c8fe7cdad142e4b8c5d97f5b57e4ea",
      "6097e82932354519a04fe3bb117cc1e5",
      "e6b763ab2e68450b909ea72f596201a5",
      "5484516688a745b0b6ba06c8ac244b3f",
      "3e8529c2c70346e6a0de958e7b604177",
      "39e8bbdd8b584fe7a623669c4df2f6b0",
      "b7ba6c0d32294dab9f01e520350d2bd8",
      "6ae7ffa65c8e4f4092720a4db908a38b",
      "90268a5dc6814d5b9441e4eee5db5b51",
      "acd36b88fe2143ed9ad755ac963712ac"
     ]
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T12:13:05.576907Z",
     "iopub.status.busy": "2026-01-02T12:13:05.576527Z",
     "iopub.status.idle": "2026-01-02T12:14:39.295848Z",
     "shell.execute_reply": "2026-01-02T12:14:39.295021Z",
     "shell.execute_reply.started": "2026-01-02T12:13:05.576870Z"
    },
    "id": "rxwujq6HtkDn",
    "outputId": "5563d49c-8079-4e06-8e71-ea3f93d1e61b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 12:13:26.412023: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767356006.815183      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767356006.935172      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767356007.931812      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767356007.931852      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767356007.931855      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767356007.931857      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c8fe7cdad142e4b8c5d97f5b57e4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6097e82932354519a04fe3bb117cc1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b763ab2e68450b909ea72f596201a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5484516688a745b0b6ba06c8ac244b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8529c2c70346e6a0de958e7b604177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e8bbdd8b584fe7a623669c4df2f6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ba6c0d32294dab9f01e520350d2bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae7ffa65c8e4f4092720a4db908a38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90268a5dc6814d5b9441e4eee5db5b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd36b88fe2143ed9ad755ac963712ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    attn_implementation=\"sdpa\",                   # Change to Flash Attention if GPU has support\n",
    "    dtype=torch.float16,                          # Change to bfloat16 if GPU has support\n",
    "    device_map=\"auto\",\n",
    "    # use_cache=True,                               # Whether to cache attention outputs to speed up inference\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,                        # Load the model in 4-bit precision to save memory\n",
    "        bnb_4bit_compute_dtype=torch.float16,     # Data type used for internal computations in quantization\n",
    "        bnb_4bit_use_double_quant=True,           # Use double quantization to improve accuracy\n",
    "        bnb_4bit_quant_type=\"nf4\"                 # Type of quantization. \"nf4\" is recommended for recent LLMs\n",
    "    )\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "ce61aa7ae3ec475e803fd0833c972c05",
      "c51a344eb0004f4fb157de53254fe9fd"
     ]
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:39.298398Z",
     "iopub.status.busy": "2026-01-02T12:14:39.297189Z",
     "iopub.status.idle": "2026-01-02T12:14:43.504962Z",
     "shell.execute_reply": "2026-01-02T12:14:43.504220Z",
     "shell.execute_reply.started": "2026-01-02T12:14:39.298367Z"
    },
    "id": "xM9Ws7gZtkDn",
    "outputId": "2c23b9fd-1dd2-424c-f202-c9c13d5b8b7b",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce61aa7ae3ec475e803fd0833c972c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/config.py:165: UserWarning: Unexpected keyword arguments ['alora_invocation_tokens', 'arrow_config', 'ensure_weight_tying', 'peft_version'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51a344eb0004f4fb157de53254fe9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/48.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 24,313,856 || All params: 1,852,091,392 || Trainable%: 1.31%\n"
     ]
    }
   ],
   "source": [
    "adapter_model = f\"JellyFush/Llama-3.2-3B-Instruct\" # Replace with your HF username or organization\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    adapter_model,\n",
    "    adapter_name=\"policy\",\n",
    "    is_trainable=True\n",
    ")\n",
    "\n",
    "# ---- Load REFERENCE adapter (frozen) ----\n",
    "model.load_adapter(\n",
    "    adapter_model,\n",
    "    adapter_name=\"ref\",\n",
    "    is_trainable=False\n",
    ")\n",
    "\n",
    "# Set the active adapter to policy for training\n",
    "model.set_adapter(\"policy\")\n",
    "\n",
    "# Enable input gradients (required for gradient checkpointing with quantized models)\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "# Enable gradient checkpointing with use_reentrant=False (required for quantized models)\n",
    "model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "\n",
    "# Verify trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable params: {trainable_params:,} || All params: {all_params:,} || Trainable%: {100 * trainable_params / all_params:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:43.506191Z",
     "iopub.status.busy": "2026-01-02T12:14:43.505872Z",
     "iopub.status.idle": "2026-01-02T12:14:50.675378Z",
     "shell.execute_reply": "2026-01-02T12:14:50.674665Z",
     "shell.execute_reply.started": "2026-01-02T12:14:43.506158Z"
    },
    "id": "uqBRFCy0tkDn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:50.678164Z",
     "iopub.status.busy": "2026-01-02T12:14:50.677875Z",
     "iopub.status.idle": "2026-01-02T12:14:52.912249Z",
     "shell.execute_reply": "2026-01-02T12:14:52.911488Z",
     "shell.execute_reply.started": "2026-01-02T12:14:50.678138Z"
    },
    "id": "W-wBdO0XtkDo",
    "outputId": "68b29f32-4c7d-4450-f83f-f738d707fe2c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ho5GuoXy0laRI450RFQ8WR9x4flz1jy9\n",
      "To: /content/full_dpo_dataset_2.json\n",
      "100%|██████████| 1.67M/1.67M [00:00<00:00, 137MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to /content/full_dpo_dataset_2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download file from Google Drive\n",
    "import os\n",
    "import gdown\n",
    "\n",
    "# https://drive.google.com/file/d/1ho5GuoXy0laRI450RFQ8WR9x4flz1jy9/view?usp=sharing\n",
    "# Google Drive file ID from the sharing link, then change the ID\n",
    "file_id = \"1ho5GuoXy0laRI450RFQ8WR9x4flz1jy9\"\n",
    "# URL for downloading\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "output_path = \"/content/full_dpo_dataset_2.json\"\n",
    "\n",
    "# Download the file\n",
    "gdown.download(url, output_path, quiet=False)\n",
    "\n",
    "print(f\"Downloaded to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "44c1630128084085a8dd28f308282477"
     ]
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:52.913743Z",
     "iopub.status.busy": "2026-01-02T12:14:52.913050Z",
     "iopub.status.idle": "2026-01-02T12:14:54.313085Z",
     "shell.execute_reply": "2026-01-02T12:14:54.312400Z",
     "shell.execute_reply.started": "2026-01-02T12:14:52.913679Z"
    },
    "id": "Fze5XZS3tkDo",
    "outputId": "53723945-0b8c-4936-c817-0be2b34c28b5",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c1630128084085a8dd28f308282477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'accepted_response', 'rejected_response'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"json\", data_files=\"/content/full_dpo_dataset_2.json\", split=\"train\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "4430f9ed689147c19f38a7a9e09de2c2"
     ]
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:54.314726Z",
     "iopub.status.busy": "2026-01-02T12:14:54.314288Z",
     "iopub.status.idle": "2026-01-02T12:14:54.388894Z",
     "shell.execute_reply": "2026-01-02T12:14:54.388021Z",
     "shell.execute_reply.started": "2026-01-02T12:14:54.314664Z"
    },
    "id": "jYmM05IztkDo",
    "outputId": "c444b622-52da-4f4c-e87f-197013d1f916",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4430f9ed689147c19f38a7a9e09de2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"\"\"Role:\n",
    "You are an expert Medical Diagnostician and Board Examiner.\n",
    "\n",
    "Task:\n",
    "Read the provided Clinical Vignette. Determine the most likely diagnosis.\n",
    "You must first generate a structured clinical reasoning process inside <think> tags, followed by the final diagnosis as plain text.\n",
    "\n",
    "Output Format:\n",
    "<think>\n",
    "[Explanation]\n",
    "</think>\n",
    "\n",
    "[Final Diagnosis Name]\n",
    "\"\"\"\n",
    "\n",
    "def create_dpo_messages(row):\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": row[\"question\"]\n",
    "            }\n",
    "        ],\n",
    "        \"chosen\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": row[\"accepted_response\"]\n",
    "            }\n",
    "        ],\n",
    "        \"rejected\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": row[\"rejected_response\"]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "ds_dpo = ds.map(\n",
    "    create_dpo_messages,\n",
    "    remove_columns=ds.column_names\n",
    ")\n",
    "\n",
    "ds_dpo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:54.390570Z",
     "iopub.status.busy": "2026-01-02T12:14:54.390005Z",
     "iopub.status.idle": "2026-01-02T12:14:54.400230Z",
     "shell.execute_reply": "2026-01-02T12:14:54.399392Z",
     "shell.execute_reply.started": "2026-01-02T12:14:54.390544Z"
    },
    "id": "eF36KnUPtkDo",
    "outputId": "f0b14408-966f-4d83-c6b0-e49333bf705f",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': [{'content': 'Role:\\nYou are an expert Medical Diagnostician and Board Examiner.\\n\\nTask:\\nRead the provided Clinical Vignette. Determine the most likely diagnosis.\\nYou must first generate a structured clinical reasoning process inside <think> tags, followed by the final diagnosis as plain text.\\n\\nOutput Format:\\n<think>\\n[Explanation]\\n</think>\\n\\n[Final Diagnosis Name]\\n',\n",
       "   'role': 'system'},\n",
       "  {'content': 'A 50-year-old male physician is medically evacuated to a high-level isolation unit after developing a febrile illness while working in Sierra Leone. His initial clinical course is dominated by severe gastrointestinal symptoms requiring aggressive fluid resuscitation. However, days after admission, his condition deteriorates significantly with the onset of profound hypoxia and respiratory failure, necessitating advanced airway management and mechanical ventilation. Chest imaging reveals diffuse pulmonary infiltrates. Diagnostic bronchoscopy is performed, and molecular testing of the bronchial aspirate reveals an extremely high viral load. Concurrently, laboratory testing identifies a parasitic co-infection. He is treated with experimental antiviral therapies and supportive care, eventually achieving full recovery. What is the most likely diagnosis?',\n",
       "   'role': 'user'}],\n",
       " 'chosen': [{'content': '<think>1. Epidemiology: The patient is a healthcare worker returning from Sierra Leone, a high-risk demographic for acquiring viral hemorrhagic fevers like Ebola Virus Disease (EVD). 2. Clinical Anchor: While EVD typically manifests with gastrointestinal and hemorrhagic symptoms, this case is anchored by the rare development of primary respiratory failure. The pathognomonic finding is the detection of high viral load in the lung fluid (bronchial aspirate), confirming direct viral invasion of the lung parenchyma (Viral Interstitial Pneumonia), rather than just secondary ARDS or bacterial superinfection. 3. Differential Exclusion: The patient has a confirmed co-infection with Plasmodium vivax (Malaria). While severe malaria can cause respiratory distress (ARDS), the specific finding of high viral RNA in the lung fluid confirms that the respiratory failure was primarily driven by the viral pneumonitis, not the parasite. 4. Confirmation: The isolation of the virus from the respiratory tract confirms the diagnosis of EVD-associated interstitial pneumonia.</think>\\nEbola Virus Disease (complicated by Ebola Interstitial Pneumonia)',\n",
       "   'role': 'assistant'}],\n",
       " 'rejected': [{'content': \"<think>1. **Clinical Presentation**: The patient presents with a severe, rapidly progressive respiratory illness, initially mimicking a bacterial pneumonia but evolving into a severe, multi-organ failure syndrome. The key diagnostic clues are the rapid deterioration from gastrointestinal symptoms to respiratory failure, the presence of diffuse pulmonary infiltrates on imaging, and the identification of a viral etiology (high viral load in bronchial aspirate) alongside a parasitic co-infection (e.g., Plasmodium falciparum or Leishmania donovani).\\n\\n2. **Viral Infection**: The high viral load in the bronchial aspirate strongly suggests a viral etiology. The specific virus causing this syndrome is not immediately clear without further molecular typing, but it could be any of several viruses known to cause severe respiratory illnesses in immunocompromised individuals, such as SARS-CoV-2, Hendra virus, or Marburg virus.\\n\\n3. **Parasitic Co-Infection**: The concurrent parasitic infection is crucial for the differential diagnosis. The patient's history of travel to a high-risk area (Sierra Leone) and the specific parasite identified (Plasmodium falciparum) aligns with the clinical scenario. This combination is highly unusual and poses significant diagnostic challenges due to the overlapping clinical presentation.\\n\\n4. **Differential Considerations**:\\n   - **SARS-CoV-2**: While SARS-CoV-2 can cause severe respiratory disease, its epidemiology and clinical presentation are distinct from the described case.\\n   - **Hendra Virus**: This virus is endemic to Australia and can cause severe respiratory disease in humans, but its transmission is limited to the Australian population.\\n   - **Marburg Virus**: This virus is also endemic to West Africa and can cause severe respiratory disease, but its transmission is more limited compared to SARS-CoV-2.\\n\\n5. **Conclusion**: Given the rapid progression from gastrointestinal symptoms to severe respiratory failure, the high viral load in the bronchial aspirate, and the concurrent parasitic infection (likely Plasmodium falciparum), the most likely diagnosis is **Marburg Virus Disease**. The rapid clinical deterioration and the specific combination of viral and parasitic infections are characteristic features of Marburg Virus Disease, which is a rare but severe form of hemorrhagic fever caused by the Marburg virus.</think>\\nMarburg Virus Disease\",\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dpo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:54.401636Z",
     "iopub.status.busy": "2026-01-02T12:14:54.401374Z",
     "iopub.status.idle": "2026-01-02T12:14:54.441297Z",
     "shell.execute_reply": "2026-01-02T12:14:54.440603Z",
     "shell.execute_reply.started": "2026-01-02T12:14:54.401610Z"
    },
    "id": "Mbmiy3IttkDo",
    "outputId": "349dae57-08fb-43ff-dcf7-ca5b2b1e7222",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 320\n",
      "Evaluation samples: 80\n"
     ]
    }
   ],
   "source": [
    "# This split the dataset by getting 1 row of each disease and put in the validation set\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "\n",
    "rows_per_disease = 5\n",
    "\n",
    "for i in range(0, len(ds_dpo), rows_per_disease):\n",
    "    chunk = list(range(i, i + rows_per_disease))\n",
    "\n",
    "    # 1 sample → validation\n",
    "    val_indices.append(chunk[0])\n",
    "\n",
    "    # remaining samples → training\n",
    "    train_indices.extend(chunk[1:])\n",
    "\n",
    "train_dataset = ds_dpo.select(train_indices)\n",
    "eval_dataset  = ds_dpo.select(val_indices)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(seed=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Evaluation samples: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:54.442870Z",
     "iopub.status.busy": "2026-01-02T12:14:54.442497Z",
     "iopub.status.idle": "2026-01-02T12:14:54.447507Z",
     "shell.execute_reply": "2026-01-02T12:14:54.446927Z",
     "shell.execute_reply.started": "2026-01-02T12:14:54.442830Z"
    },
    "id": "Y-j27tHKtkDp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "      r=16,\n",
    "      lora_alpha=16,\n",
    "      # lora_dropout=0.05,\n",
    "      target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:54.448429Z",
     "iopub.status.busy": "2026-01-02T12:14:54.448219Z",
     "iopub.status.idle": "2026-01-02T12:14:54.573641Z",
     "shell.execute_reply": "2026-01-02T12:14:54.573026Z",
     "shell.execute_reply.started": "2026-01-02T12:14:54.448407Z"
    },
    "id": "gsuRh-_OtkDp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from trl import DPOConfig\n",
    "\n",
    "training_args = DPOConfig(\n",
    "    output_dir=output_dir,\n",
    "    beta=0.1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-6,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=100,\n",
    "    logging_steps=1,\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    model_adapter_name=\"policy\",\n",
    "    ref_adapter_name=\"ref\",\n",
    "    max_length=2048,\n",
    "    # use_liger_kernel=True,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    # Evaluation settings\n",
    "    eval_strategy=\"steps\",          # Run evaluation every eval_steps\n",
    "    eval_steps=40,                  # Evaluate every 50 steps\n",
    "    # eval_strategy=\"epoch\",        # Alternative: evaluate at end of each epoch\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "da9cae78db2245bd811f8350b1705680",
      "fac19c4bb5bd4a228d332f0687484b37",
      "8952104bd0f74e07ac20925694d4c75b",
      "d09cbe698e6b4f6f982ad9465ff129f6",
      "f6c58ff146874acca749e308e35dc176",
      "d92a14753e2a4c34ac6206557717147c"
     ]
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:54.574975Z",
     "iopub.status.busy": "2026-01-02T12:14:54.574616Z",
     "iopub.status.idle": "2026-01-02T12:14:59.772821Z",
     "shell.execute_reply": "2026-01-02T12:14:59.772070Z",
     "shell.execute_reply.started": "2026-01-02T12:14:54.574938Z"
    },
    "id": "9jndVWL_tkDp",
    "outputId": "0d5c5157-4a28-430a-e0ec-1013a523507e",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9cae78db2245bd811f8350b1705680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in train dataset:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac19c4bb5bd4a228d332f0687484b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8952104bd0f74e07ac20925694d4c75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09cbe698e6b4f6f982ad9465ff129f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in eval dataset:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c58ff146874acca749e308e35dc176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92a14753e2a4c34ac6206557717147c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import DPOTrainer\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,           # Using adapter-based reference via ref_adapter_name\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    # peft_config=peft_config,  # Don't pass this when using existing adapters\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:14:59.774219Z",
     "iopub.status.busy": "2026-01-02T12:14:59.773838Z",
     "iopub.status.idle": "2026-01-02T15:22:37.703258Z",
     "shell.execute_reply": "2026-01-02T15:22:37.702547Z",
     "shell.execute_reply.started": "2026-01-02T12:14:59.774193Z"
    },
    "id": "L0dYUifatkDp",
    "outputId": "c647d2f8-269d-4da5-d884-a7dcdb1bdc7d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260102_121500-2z4426ta</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leviettin/DPOTraining/runs/2z4426ta' target=\"_blank\">dry-sun-21</a></strong> to <a href='https://wandb.ai/leviettin/DPOTraining' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/leviettin/DPOTraining' target=\"_blank\">https://wandb.ai/leviettin/DPOTraining</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/leviettin/DPOTraining/runs/2z4426ta' target=\"_blank\">https://wandb.ai/leviettin/DPOTraining/runs/2z4426ta</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 3:06:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.306412</td>\n",
       "      <td>0.322087</td>\n",
       "      <td>-0.721672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.043760</td>\n",
       "      <td>-439.709290</td>\n",
       "      <td>-393.535065</td>\n",
       "      <td>-0.580774</td>\n",
       "      <td>-0.115414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.155963</td>\n",
       "      <td>0.508115</td>\n",
       "      <td>-1.331572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.839687</td>\n",
       "      <td>-437.849030</td>\n",
       "      <td>-399.634064</td>\n",
       "      <td>-0.596159</td>\n",
       "      <td>-0.127493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.102654</td>\n",
       "      <td>0.609010</td>\n",
       "      <td>-1.732829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.341839</td>\n",
       "      <td>-436.840088</td>\n",
       "      <td>-403.646637</td>\n",
       "      <td>-0.606984</td>\n",
       "      <td>-0.136768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.087870</td>\n",
       "      <td>0.655627</td>\n",
       "      <td>-1.863619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.519246</td>\n",
       "      <td>-436.373871</td>\n",
       "      <td>-404.954498</td>\n",
       "      <td>-0.609569</td>\n",
       "      <td>-0.138619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=160, training_loss=0.23445073124021293, metrics={'train_runtime': 11256.027, 'train_samples_per_second': 0.028, 'train_steps_per_second': 0.014, 'total_flos': 0.0, 'train_loss': 0.23445073124021293, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "67457b7f5d284c3199eb2054ab789f93",
      "a84d070aefad4780b1e4913df656569a",
      "655c70454f4641b7b3f62507c8319a04",
      "4ff965b5890942d5a442ba521ac9c948"
     ]
    },
    "execution": {
     "iopub.execute_input": "2026-01-02T15:22:37.704511Z",
     "iopub.status.busy": "2026-01-02T15:22:37.704280Z",
     "iopub.status.idle": "2026-01-02T15:22:48.161041Z",
     "shell.execute_reply": "2026-01-02T15:22:48.160252Z",
     "shell.execute_reply.started": "2026-01-02T15:22:37.704487Z"
    },
    "id": "ODIXU2FgtkDq",
    "outputId": "f7a8a52d-c406-457d-f6e7-821dba066253",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67457b7f5d284c3199eb2054ab789f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84d070aefad4780b1e4913df656569a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655c70454f4641b7b3f62507c8319a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff965b5890942d5a442ba521ac9c948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Llama-3.2-3B-Instruct-DPO and Llama-3.2-3B-Instruct-DPO\n",
      "Pushed to Hugging Face Hub: JellyFush/Llama-3.2-3B-Instruct-DPO\n"
     ]
    }
   ],
   "source": [
    "# Save the trained adapter locally\n",
    "trainer.save_model(output_dir)\n",
    "\n",
    "# Save the PEFT adapter separately\n",
    "model.save_pretrained(f\"{output_dir}\")\n",
    "\n",
    "# Push to Hugging Face Hub using trainer (recommended - handles model + tokenizer)\n",
    "trainer.push_to_hub(f\"{output_dir}\", token=hf_token)\n",
    "\n",
    "print(f\"Model saved to {output_dir} and {output_dir}\")\n",
    "print(f\"Pushed to Hugging Face Hub: JellyFush/{output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
