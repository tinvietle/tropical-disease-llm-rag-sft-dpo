{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12297,
     "status": "ok",
     "timestamp": 1763518816979,
     "user": {
      "displayName": "Nguyen Nguyen Khoi",
      "userId": "04597279446684933673"
     },
     "user_tz": -420
    },
    "id": "SvhYJyX9hbnT",
    "outputId": "8723fb59-7bc7-4662-e8ac-02f023786289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
      "Collecting pdfminer.six==20251107 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
      "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20251107 pdfplumber-0.11.8 pypdfium2-5.0.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install pdfplumber google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6eXEqE1mjHV"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pdfplumber\n",
    "from google import genai\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36593,
     "status": "ok",
     "timestamp": 1763518885614,
     "user": {
      "displayName": "Nguyen Nguyen Khoi",
      "userId": "04597279446684933673"
     },
     "user_tz": -420
    },
    "id": "IOQg_feqmlcR",
    "outputId": "cae488d0-6329-434e-e50b-f6ac689c4cd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_UpnKX6msJa"
   },
   "outputs": [],
   "source": [
    "# Pass Gemini API key\n",
    "client = genai.Client(api_key=\"YOUR_API_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HsudCHjm01i"
   },
   "outputs": [],
   "source": [
    "# Extract text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from PDF file with 2-column format support using pdfplumber\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page_num, page in enumerate(pdf.pages):\n",
    "                # Get page dimensions\n",
    "                page_width = page.width\n",
    "                page_height = page.height\n",
    "\n",
    "                # Define left column (0 to middle)\n",
    "                left_bbox = (0, 0, page_width / 2, page_height)\n",
    "\n",
    "                # Define right column (middle to end)\n",
    "                right_bbox = (page_width / 2, 0, page_width, page_height)\n",
    "\n",
    "                # Extract left column text\n",
    "                left_crop = page.crop(left_bbox)\n",
    "                left_text = left_crop.extract_text() or \"\"\n",
    "\n",
    "                # Extract right column text\n",
    "                right_crop = page.crop(right_bbox)\n",
    "                right_text = right_crop.extract_text() or \"\"\n",
    "\n",
    "                # Combine left then right\n",
    "                page_text = left_text + \"\\n\" + right_text + \"\\n\"\n",
    "                text += page_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qp_JiY3Pm6J9"
   },
   "outputs": [],
   "source": [
    "# Clean text with Gemini\n",
    "def clean_text_with_gemini(raw_text):\n",
    "    \"\"\"Use Gemini AI to clean and extract only paragraph text, removing image/graph references\"\"\"\n",
    "    prompt = \"\"\"You are a text cleaning assistant. Your task is to clean medical textbook content.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Extract ONLY the main body text (paragraphs of content)\n",
    "2. REMOVE all text related to:\n",
    "   - Figure captions and references (e.g., \"Figure 1.2\", \"See Figure 3\")\n",
    "   - Table captions and references (e.g., \"Table 2.1\", \"as shown in Table\")\n",
    "   - Graph descriptions and references\n",
    "   - Image descriptions and references\n",
    "   - Box/sidebar content labels\n",
    "   - Page numbers\n",
    "   - Headers and footers\n",
    "   - References to visual elements (e.g., \"shown in the diagram\", \"illustrated in\")\n",
    "3. Keep all medical terminology, drug names, and clinical information\n",
    "4. Preserve paragraph structure with line breaks between paragraphs\n",
    "5. Keep section headings if they are part of the main text flow\n",
    "6. Remove any OCR artifacts or garbled text\n",
    "7. Start with KEY FEATURES, INTRODUCTION, EPIDEMIOLOGY, etc.\n",
    "\n",
    "---\n",
    "SAMPLE OUTPUT's first few lines:\n",
    "\n",
    "KEY FEATURES\n",
    "• Trichomoniasis is a common, sexually transmitted disease caused by a protozoan parasite that infects the urogenital tract of men and women.\n",
    "• The vagina is the most common site of infection in women.\n",
    "• Many infected women are asymptomatic, but clinical features include vaginal discharge, often yellow or green, often frothy; vulvovaginal irritation; and dysuria.\n",
    "• The urethra is the most common site of infection in men.\n",
    "• Most men with trichomoniasis do not have signs or symptoms; however, some men may exhibit urethral irritation and discharge or mild burning after urination or ejaculation.\n",
    "• Traditionally, diagnosis and differential diagnosis may be made by wet mount of vaginal material; nucleic acid amplification techniques are available.\n",
    "• Trichomoniasis is treated with oral 5′-nitroimidazoles, although resistance is developing.\n",
    "\n",
    "INTRODUCTION\n",
    "Trichomoniasis is a common, worldwide, urogenital infection with Trichomonas vaginalis. It is a frequent cause of symptomatic vaginitis and a less common cause of nongonococcal urethritis (NGU).\n",
    "\n",
    "EPIDEMIOLOGY\n",
    "Trichomoniasis is transmitted primarily by penile–vaginal and possibly by penile–anal coitus. Because it is sexually transmitted, it is strikingly associated with higher risk for other sexually transmitted infections (STIs), and coincident STIs should be sought.\n",
    "---\n",
    "\n",
    "Return ONLY the cleaned text. Do not add any commentary or explanations.\n",
    "\n",
    "---\n",
    "TEXT TO CLEAN:\n",
    "\n",
    "\"\"\" + raw_text\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1-thi8Zm_Jg"
   },
   "outputs": [],
   "source": [
    "# Save text to file\n",
    "def save_text_to_file(text, pdf_path, output_dir=\"/content/drive/MyDrive/LMM/demo_kz/disease_chapters_text\"):\n",
    "    \"\"\"Save cleaned text to a .txt file\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Generate text filename based on PDF name\n",
    "    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    txt_filename = f\"{pdf_name}.txt\"\n",
    "    txt_path = os.path.join(output_dir, txt_filename)\n",
    "\n",
    "    # Save text to file\n",
    "    try:\n",
    "        with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(text)\n",
    "        print(f\"✓ Text saved to: {txt_path}\")\n",
    "        return txt_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving text file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2OGTr5nnfql"
   },
   "outputs": [],
   "source": [
    "# Process all PDFs\n",
    "def process_all_pdfs_to_text(folder_path, selected_indices=None, output_dir=\"/content/drive/MyDrive/LMM/demo_kz/disease_chapters_text\"):\n",
    "    \"\"\"Process all PDF files in the specified folder and extract clean text\"\"\"\n",
    "\n",
    "    # Find all PDF files in the folder\n",
    "    pdf_pattern = os.path.join(folder_path, \"*.pdf\")\n",
    "    pdf_files = sorted(glob.glob(pdf_pattern))\n",
    "\n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in folder: {folder_path}\")\n",
    "        return\n",
    "\n",
    "    # Filter by selected indices if provided\n",
    "    if selected_indices:\n",
    "        selected_files = []\n",
    "        for idx in selected_indices:\n",
    "            if 1 <= idx <= len(pdf_files):\n",
    "                selected_files.append(pdf_files[idx - 1])\n",
    "            else:\n",
    "                print(f\"Warning: Index {idx} is out of range (1-{len(pdf_files)})\")\n",
    "        pdf_files = selected_files\n",
    "\n",
    "    if not pdf_files:\n",
    "        print(\"No valid files selected for processing\")\n",
    "        return\n",
    "\n",
    "    # Filter out already processed files\n",
    "    unprocessed_files = []\n",
    "    already_processed = []\n",
    "\n",
    "    for pdf_path in pdf_files:\n",
    "        pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "        txt_filename = f\"{pdf_name}.txt\"\n",
    "        txt_path = os.path.join(output_dir, txt_filename)\n",
    "\n",
    "        if os.path.exists(txt_path):\n",
    "            already_processed.append(os.path.basename(pdf_path))\n",
    "        else:\n",
    "            unprocessed_files.append(pdf_path)\n",
    "\n",
    "    # Print status\n",
    "    print(f\"Total PDF files found: {len(pdf_files)}\")\n",
    "    print(f\"Already processed: {len(already_processed)}\")\n",
    "    print(f\"Need to process: {len(unprocessed_files)}\")\n",
    "\n",
    "    if already_processed:\n",
    "        print(f\"\\nAlready processed files ({len(already_processed)}):\")\n",
    "        for filename in already_processed[:10]:  # Show first 10\n",
    "            print(f\"  ✓ {filename}\")\n",
    "        if len(already_processed) > 10:\n",
    "            print(f\"  ... and {len(already_processed) - 10} more\")\n",
    "\n",
    "    if not unprocessed_files:\n",
    "        print(\"\\nAll files have already been processed!\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nFiles to process ({len(unprocessed_files)}):\")\n",
    "    for i, pdf_file in enumerate(unprocessed_files, 1):\n",
    "        print(f\"  {i}. {os.path.basename(pdf_file)}\")\n",
    "\n",
    "    processed_count = 0\n",
    "    failed_count = 0\n",
    "\n",
    "    for pdf_path in unprocessed_files:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {os.path.basename(pdf_path)}\")\n",
    "        print('='*60)\n",
    "\n",
    "        try:\n",
    "            # Extract raw text from PDF\n",
    "            raw_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "            if raw_text:\n",
    "                print(f\"✓ Extracted raw text ({len(raw_text)} characters)\")\n",
    "\n",
    "                # Clean text using Gemini AI\n",
    "                cleaned_text = clean_text_with_gemini(raw_text)\n",
    "                print(f\"✓ Cleaned text ({len(cleaned_text)} characters)\")\n",
    "\n",
    "                # Save to text file\n",
    "                txt_path = save_text_to_file(cleaned_text, pdf_path, output_dir)\n",
    "\n",
    "                if txt_path:\n",
    "                    processed_count += 1\n",
    "                    print(f\"✓ Successfully processed: {os.path.basename(pdf_path)}\")\n",
    "                else:\n",
    "                    failed_count += 1\n",
    "                    print(f\"✗ Failed to save text for: {os.path.basename(pdf_path)}\")\n",
    "            else:\n",
    "                failed_count += 1\n",
    "                print(f\"✗ Failed to extract text from: {os.path.basename(pdf_path)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_count += 1\n",
    "            print(f\"✗ Error processing {os.path.basename(pdf_path)}: {e}\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print('='*60)\n",
    "    print(f\"Total files in folder: {len(pdf_files)}\")\n",
    "    print(f\"Already processed (skipped): {len(already_processed)}\")\n",
    "    print(f\"Newly processed: {processed_count}\")\n",
    "    print(f\"Failed: {failed_count}\")\n",
    "    print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62727,
     "status": "ok",
     "timestamp": 1763518990965,
     "user": {
      "displayName": "Nguyen Nguyen Khoi",
      "userId": "04597279446684933673"
     },
     "user_tz": -420
    },
    "id": "pKLXuDnmn_3v",
    "outputId": "29dea602-97ba-46a3-9bff-21a86489f6fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDF files found: 1\n",
      "Already processed: 0\n",
      "Need to process: 1\n",
      "\n",
      "Files to process (1):\n",
      "  1. 1_Tropical_Lung_Diseases.pdf\n",
      "\n",
      "============================================================\n",
      "Processing: 1_Tropical_Lung_Diseases.pdf\n",
      "============================================================\n",
      "✓ Extracted raw text (28906 characters)\n",
      "✓ Cleaned text (20417 characters)\n",
      "✓ Text saved to: /content/drive/MyDrive/LMM/demo_kz/disease_chapters_text/1_Tropical_Lung_Diseases.txt\n",
      "✓ Successfully processed: 1_Tropical_Lung_Diseases.pdf\n",
      "\n",
      "============================================================\n",
      "PROCESSING SUMMARY\n",
      "============================================================\n",
      "Total files in folder: 1\n",
      "Already processed (skipped): 0\n",
      "Newly processed: 1\n",
      "Failed: 0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Set paths and run\n",
    "folder_path = \"/content/drive/MyDrive/LMM/demo_kz/disease_chapters_demo\"\n",
    "output_text_dir = \"/content/drive/MyDrive/LMM/demo_kz/disease_chapters_text\"\n",
    "\n",
    "# Check if folder exists\n",
    "if os.path.exists(folder_path):\n",
    "    process_all_pdfs_to_text(folder_path, output_dir=output_text_dir)\n",
    "else:\n",
    "    print(f\"Folder not found: {folder_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
